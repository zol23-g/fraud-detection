{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fraud_data=pd.read_csv('../data/processed/fraud_data.csv')\n",
    "credit_data=pd.read_csv('../data/processed/creditcard_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'user_id', 'signup_time', 'purchase_time',\n",
       "       'purchase_value', 'device_id', 'source', 'browser', 'sex', 'age',\n",
       "       'ip_address', 'class', 'ip_address_int', 'country', 'transaction_freq',\n",
       "       'transaction_velocity', 'hour_of_day', 'day_of_week', 'source_encoded',\n",
       "       'browser_encoded', 'sex_encoded'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 151112 entries, 0 to 151111\n",
      "Data columns (total 21 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   Unnamed: 0            151112 non-null  int64  \n",
      " 1   user_id               151112 non-null  int64  \n",
      " 2   signup_time           151112 non-null  object \n",
      " 3   purchase_time         151112 non-null  object \n",
      " 4   purchase_value        151112 non-null  float64\n",
      " 5   device_id             151112 non-null  object \n",
      " 6   source                151112 non-null  object \n",
      " 7   browser               151112 non-null  object \n",
      " 8   sex                   151112 non-null  object \n",
      " 9   age                   151112 non-null  float64\n",
      " 10  ip_address            151112 non-null  float64\n",
      " 11  class                 151112 non-null  int64  \n",
      " 12  ip_address_int        151112 non-null  int64  \n",
      " 13  country               151112 non-null  object \n",
      " 14  transaction_freq      151112 non-null  float64\n",
      " 15  transaction_velocity  151112 non-null  float64\n",
      " 16  hour_of_day           151112 non-null  int64  \n",
      " 17  day_of_week           151112 non-null  int64  \n",
      " 18  source_encoded        151112 non-null  int64  \n",
      " 19  browser_encoded       151112 non-null  int64  \n",
      " 20  sex_encoded           151112 non-null  int64  \n",
      "dtypes: float64(5), int64(9), object(7)\n",
      "memory usage: 24.2+ MB\n"
     ]
    }
   ],
   "source": [
    "fraud_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8',\n",
       "       'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18',\n",
       "       'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28',\n",
       "       'Amount', 'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Time        V1        V2        V3        V4        V5  \\\n",
       "0           0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321   \n",
       "1           1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018   \n",
       "2           2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198   \n",
       "3           3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4           4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193   \n",
       "\n",
       "         V6        V7        V8  ...       V21       V22       V23       V24  \\\n",
       "0  0.462388  0.239599  0.098698  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1 -0.082361 -0.078803  0.085102  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  1.800499  0.791461  0.247676  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  1.247203  0.237609  0.377436  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4  0.095921  0.592941 -0.270533  ... -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature and Target Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraud data target and features separation\n",
    "X_fraud = fraud_data[['purchase_value', 'transaction_freq', 'transaction_velocity', 'hour_of_day', 'day_of_week', 'source_encoded', 'browser_encoded', 'sex_encoded']]\n",
    "y_fraud = fraud_data['class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit card data target and features separation\n",
    "X_credit = credit_data.drop({'Class','Unnamed: 0','Time'}, axis=1)\n",
    "y_credit = credit_data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_credit.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split Fraud_Data into training and test sets\n",
    "X_train_fraud, X_test_fraud, y_train_fraud, y_test_fraud = train_test_split(X_fraud, y_fraud, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split Creditcard data into training and test sets\n",
    "X_train_credit, X_test_credit, y_train_credit, y_test_credit = train_test_split(X_credit, y_credit, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud Data Logistic Regression Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     41117\n",
      "           1       0.00      0.00      0.00      4217\n",
      "\n",
      "    accuracy                           0.91     45334\n",
      "   macro avg       0.45      0.50      0.48     45334\n",
      "weighted avg       0.82      0.91      0.86     45334\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zelalem.wubet\\projects\\personal\\ten-academy\\fraud-detection\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\zelalem.wubet\\projects\\personal\\ten-academy\\fraud-detection\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\zelalem.wubet\\projects\\personal\\ten-academy\\fraud-detection\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credit Card Data Logistic Regression Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     84984\n",
      "           1       0.80      0.50      0.61       134\n",
      "\n",
      "    accuracy                           1.00     85118\n",
      "   macro avg       0.90      0.75      0.81     85118\n",
      "weighted avg       1.00      1.00      1.00     85118\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zelalem.wubet\\projects\\personal\\ten-academy\\fraud-detection\\env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "# Train the model on Fraud_Data\n",
    "lr_model.fit(X_train_fraud, y_train_fraud)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_fraud_lr = lr_model.predict(X_test_fraud)\n",
    "print(\"Fraud Data Logistic Regression Report:\")\n",
    "print(classification_report(y_test_fraud, y_pred_fraud_lr))\n",
    "\n",
    "# Train the model on Creditcard data\n",
    "lr_model.fit(X_train_credit, y_train_credit)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_credit_lr = lr_model.predict(X_test_credit)\n",
    "print(\"Credit Card Data Logistic Regression Report:\")\n",
    "print(classification_report(y_test_credit, y_pred_credit_lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud Data Decision Tree Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95     41117\n",
      "           1       0.50      0.56      0.53      4217\n",
      "\n",
      "    accuracy                           0.91     45334\n",
      "   macro avg       0.73      0.75      0.74     45334\n",
      "weighted avg       0.91      0.91      0.91     45334\n",
      "\n",
      "Credit Card Data Decision Tree Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     84984\n",
      "           1       0.71      0.78      0.74       134\n",
      "\n",
      "    accuracy                           1.00     85118\n",
      "   macro avg       0.86      0.89      0.87     85118\n",
      "weighted avg       1.00      1.00      1.00     85118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize Decision Tree model\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "# Train the model on Fraud_Data\n",
    "dt_model.fit(X_train_fraud, y_train_fraud)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_fraud_dt = dt_model.predict(X_test_fraud)\n",
    "print(\"Fraud Data Decision Tree Report:\")\n",
    "print(classification_report(y_test_fraud, y_pred_fraud_dt))\n",
    "\n",
    "# Train the model on Creditcard data\n",
    "dt_model.fit(X_train_credit, y_train_credit)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_credit_dt = dt_model.predict(X_test_credit)\n",
    "print(\"Credit Card Data Decision Tree Report:\")\n",
    "print(classification_report(y_test_credit, y_pred_credit_dt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/26 14:35:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training completed for fraud_detection_rf.\n",
      "Accuracy: 0.9569638681784092\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     41117\n",
      "           1       0.99      0.54      0.70      4217\n",
      "\n",
      "    accuracy                           0.96     45334\n",
      "   macro avg       0.97      0.77      0.84     45334\n",
      "weighted avg       0.96      0.96      0.95     45334\n",
      "\n",
      "Trained model saved to ../models/fraud_detection_rf_model.pkl\n",
      "Model fraud_detection_rf loaded successfully as a RandomForestClassifier instance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/26 14:40:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training completed for creditcard_fraud_rf.\n",
      "Accuracy: 0.9994948189572124\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     84984\n",
      "           1       0.95      0.72      0.82       134\n",
      "\n",
      "    accuracy                           1.00     85118\n",
      "   macro avg       0.98      0.86      0.91     85118\n",
      "weighted avg       1.00      1.00      1.00     85118\n",
      "\n",
      "Trained model saved to ../models/creditcard_fraud_rf_model.pkl\n",
      "Model creditcard_fraud_rf loaded successfully as a RandomForestClassifier instance.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Ensure the models directory exists\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Initialize Random Forest model\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Function to train, evaluate, and save the model\n",
    "def train_and_evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    with mlflow.start_run():\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        \n",
    "        # Log parameters and metrics with MLflow\n",
    "        mlflow.log_param(\"model\", model_name)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        \n",
    "        # Log the model with MLflow\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        \n",
    "        print(f\"Model training completed for {model_name}.\")\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(f\"Classification Report:\\n{report}\")\n",
    "        \n",
    "        # Save the trained model to the models folder using joblib\n",
    "        model_path = f'../models/{model_name}_model.pkl'\n",
    "        joblib.dump(model, model_path)\n",
    "        \n",
    "        print(f\"Trained model saved to {model_path}\")\n",
    "        \n",
    "        # Verify that the model can be reloaded successfully\n",
    "        loaded_model = joblib.load(model_path)\n",
    "        if isinstance(loaded_model, RandomForestClassifier):\n",
    "            print(f\"Model {model_name} loaded successfully as a RandomForestClassifier instance.\")\n",
    "        else:\n",
    "            print(f\"Warning: Model {model_name} did not load as RandomForestClassifier.\")\n",
    "\n",
    "# Train and evaluate model on Fraud_Data\n",
    "train_and_evaluate_model(rf_model, X_train_fraud, X_test_fraud, y_train_fraud, y_test_fraud, 'fraud_detection_rf')\n",
    "\n",
    "# Train and evaluate model on Creditcard data\n",
    "train_and_evaluate_model(rf_model, X_train_credit, X_test_credit, y_train_credit, y_test_credit, 'creditcard_fraud_rf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud Data Gradient Boosting Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     41117\n",
      "           1       1.00      0.54      0.70      4217\n",
      "\n",
      "    accuracy                           0.96     45334\n",
      "   macro avg       0.98      0.77      0.84     45334\n",
      "weighted avg       0.96      0.96      0.95     45334\n",
      "\n",
      "Credit Card Data Gradient Boosting Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     84984\n",
      "           1       0.86      0.48      0.62       134\n",
      "\n",
      "    accuracy                           1.00     85118\n",
      "   macro avg       0.93      0.74      0.81     85118\n",
      "weighted avg       1.00      1.00      1.00     85118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier()\n",
    "\n",
    "# Train the model on Fraud_Data\n",
    "gb_model.fit(X_train_fraud, y_train_fraud)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_fraud_gb = gb_model.predict(X_test_fraud)\n",
    "print(\"Fraud Data Gradient Boosting Report:\")\n",
    "print(classification_report(y_test_fraud, y_pred_fraud_gb))\n",
    "\n",
    "# Train the model on Creditcard data\n",
    "gb_model.fit(X_train_credit, y_train_credit)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_credit_gb = gb_model.predict(X_test_credit)\n",
    "print(\"Credit Card Data Gradient Boosting Report:\")\n",
    "print(classification_report(y_test_credit, y_pred_credit_gb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud Data MLP Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97     41117\n",
      "           1       0.90      0.55      0.68      4217\n",
      "\n",
      "    accuracy                           0.95     45334\n",
      "   macro avg       0.93      0.77      0.83     45334\n",
      "weighted avg       0.95      0.95      0.95     45334\n",
      "\n",
      "Credit Card Data MLP Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     84984\n",
      "           1       0.37      0.43      0.40       134\n",
      "\n",
      "    accuracy                           1.00     85118\n",
      "   macro avg       0.69      0.72      0.70     85118\n",
      "weighted avg       1.00      1.00      1.00     85118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Initialize Multi-Layer Perceptron model\n",
    "mlp_model = MLPClassifier(max_iter=500)\n",
    "\n",
    "# Train the model on Fraud_Data\n",
    "mlp_model.fit(X_train_fraud, y_train_fraud)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_fraud_mlp = mlp_model.predict(X_test_fraud)\n",
    "print(\"Fraud Data MLP Report:\")\n",
    "print(classification_report(y_test_fraud, y_pred_fraud_mlp))\n",
    "\n",
    "# Train the model on Creditcard data\n",
    "mlp_model.fit(X_train_credit, y_train_credit)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_credit_mlp = mlp_model.predict(X_test_credit)\n",
    "print(\"Credit Card Data MLP Report:\")\n",
    "print(classification_report(y_test_credit, y_pred_credit_mlp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zelalem.wubet\\fraud-detection\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "The shape of the shap_values matrix does not match the shape of the provided data matrix.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 59\u001b[0m\n\u001b[0;32m     56\u001b[0m     plt\u001b[38;5;241m.\u001b[39mclf()\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Explain Fraud Detection Model\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m \u001b[43mshap_explain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrf_model_fraud\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_fraud\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfraud_detection_rf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m lime_explain(rf_model_fraud, X_test_fraud, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfraud_detection_rf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Explain Credit Card Fraud Detection Model\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[7], line 34\u001b[0m, in \u001b[0;36mshap_explain\u001b[1;34m(model, X, model_name)\u001b[0m\n\u001b[0;32m     31\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m explainer\u001b[38;5;241m.\u001b[39mshap_values(X)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Summary Plot\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshap_values\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m plt\u001b[38;5;241m.\u001b[39msavefig(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../explainability/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_shap_summary_plot.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     36\u001b[0m plt\u001b[38;5;241m.\u001b[39mclf()\n",
      "File \u001b[1;32mc:\\Users\\zelalem.wubet\\fraud-detection\\venv\\Lib\\site-packages\\shap\\plots\\_beeswarm.py:543\u001b[0m, in \u001b[0;36msummary_legacy\u001b[1;34m(shap_values, features, feature_names, max_display, plot_type, color, axis_color, title, alpha, show, sort, color_bar, plot_size, layered_violin_max_num_bins, class_names, class_inds, color_bar_label, cmap, show_values_in_legend, use_log_scale)\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, shape_msg \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Perhaps the extra column in the shap_values matrix is the \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[0;32m    541\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant offset? Of so just pass shap_values[:,:-1].\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    542\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 543\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m num_features \u001b[38;5;241m==\u001b[39m features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], shape_msg\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    546\u001b[0m     feature_names \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([labels[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFEATURE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_features)])\n",
      "\u001b[1;31mAssertionError\u001b[0m: The shape of the shap_values matrix does not match the shape of the provided data matrix."
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load the trained models\n",
    "with open('../models/fraud_detection_rf_model.pkl', 'rb') as model_file:\n",
    "    rf_model_fraud = joblib.load(model_file)\n",
    "    print(type(rf_model_fraud))  # Debugging line\n",
    "\n",
    "with open('../models/creditcard_fraud_rf_model.pkl', 'rb') as model_file:\n",
    "    rf_model_credit = joblib.load(model_file)\n",
    "    print(type(rf_model_credit))  # Debugging line\n",
    "\n",
    "# Ensure the models are RandomForestClassifier objects\n",
    "if not isinstance(rf_model_fraud, RandomForestClassifier):\n",
    "    raise TypeError(\"rf_model_fraud is not a RandomForestClassifier\")\n",
    "\n",
    "if not isinstance(rf_model_credit, RandomForestClassifier):\n",
    "    raise TypeError(\"rf_model_credit is not a RandomForestClassifier\")\n",
    "\n",
    "# Ensure the explainability directory exists\n",
    "os.makedirs('../explainability', exist_ok=True)\n",
    "\n",
    "# SHAP Explainability\n",
    "def shap_explain(model, X, model_name):\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X)\n",
    "\n",
    "    # Summary Plot\n",
    "    shap.summary_plot(shap_values[1], X, show=False)\n",
    "    plt.savefig(f'../explainability/{model_name}_shap_summary_plot.png')\n",
    "    plt.clf()\n",
    "\n",
    "    # Force Plot (for the first instance)\n",
    "    shap.force_plot(explainer.expected_value[1], shap_values[1][0], X.iloc[0], show=False, matplotlib=True)\n",
    "    plt.savefig(f'../explainability/{model_name}_shap_force_plot.png')\n",
    "    plt.clf()\n",
    "\n",
    "    # Dependence Plot (for the first feature)\n",
    "    shap.dependence_plot(0, shap_values[1], X, show=False)\n",
    "    plt.savefig(f'../explainability/{model_name}_shap_dependence_plot.png')\n",
    "    plt.clf()\n",
    "\n",
    "# LIME Explainability\n",
    "def lime_explain(model, X, model_name):\n",
    "    explainer = lime.lime_tabular.LimeTabularExplainer(X.values, feature_names=X.columns, class_names=['Non-Fraud', 'Fraud'], discretize_continuous=True)\n",
    "    exp = explainer.explain_instance(X.iloc[0], model.predict_proba, num_features=10)\n",
    "\n",
    "    # Feature Importance Plot\n",
    "    exp.as_pyplot_figure()\n",
    "    plt.savefig(f'../explainability/{model_name}_lime_feature_importance.png')\n",
    "    plt.clf()\n",
    "\n",
    "# # Explain Fraud Detection Model\n",
    "# shap_explain(rf_model_fraud, X_test_fraud, 'fraud_detection_rf')\n",
    "# lime_explain(rf_model_fraud, X_test_fraud, 'fraud_detection_rf')\n",
    "\n",
    "# # Explain Credit Card Fraud Detection Model\n",
    "# shap_explain(rf_model_credit, X_test_credit, 'creditcard_fraud_rf')\n",
    "# lime_explain(rf_model_credit, X_test_credit, 'creditcard_fraud_rf')\n",
    "\n",
    "# print(\"Model explainability completed and plots saved in the 'explainability' folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/26 14:55:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training completed for fraud_detection_rf.\n",
      "Accuracy: 0.9569418096792695\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     41117\n",
      "           1       0.99      0.54      0.70      4217\n",
      "\n",
      "    accuracy                           0.96     45334\n",
      "   macro avg       0.97      0.77      0.84     45334\n",
      "weighted avg       0.96      0.96      0.95     45334\n",
      "\n",
      "Trained model saved to ../models/fraud_detection_rf_model.pkl\n",
      "Model fraud_detection_rf loaded successfully as a RandomForestClassifier instance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/26 14:59:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training completed for creditcard_fraud_rf.\n",
      "Accuracy: 0.9995183157499001\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     84984\n",
      "           1       0.95      0.73      0.83       134\n",
      "\n",
      "    accuracy                           1.00     85118\n",
      "   macro avg       0.98      0.87      0.91     85118\n",
      "weighted avg       1.00      1.00      1.00     85118\n",
      "\n",
      "Trained model saved to ../models/creditcard_fraud_rf_model.pkl\n",
      "Model creditcard_fraud_rf loaded successfully as a RandomForestClassifier instance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/26 14:59:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training completed for fraud_detection_dt.\n",
      "Accuracy: 0.9066484316407112\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95     41117\n",
      "           1       0.50      0.56      0.53      4217\n",
      "\n",
      "    accuracy                           0.91     45334\n",
      "   macro avg       0.73      0.75      0.74     45334\n",
      "weighted avg       0.91      0.91      0.91     45334\n",
      "\n",
      "Trained model saved to ../models/fraud_detection_dt_model.pkl\n",
      "Model fraud_detection_dt loaded successfully as a DecisionTreeClassifier instance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/26 15:00:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training completed for creditcard_fraud_dt.\n",
      "Accuracy: 0.9991071218778637\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     84984\n",
      "           1       0.69      0.78      0.73       134\n",
      "\n",
      "    accuracy                           1.00     85118\n",
      "   macro avg       0.85      0.89      0.87     85118\n",
      "weighted avg       1.00      1.00      1.00     85118\n",
      "\n",
      "Trained model saved to ../models/creditcard_fraud_dt_model.pkl\n",
      "Model creditcard_fraud_dt loaded successfully as a DecisionTreeClassifier instance.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Ensure the models directory exists\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Function to train, evaluate, and save the model\n",
    "def train_and_evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    with mlflow.start_run():\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        \n",
    "        # Log parameters and metrics with MLflow\n",
    "        mlflow.log_param(\"model\", model_name)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        \n",
    "        # Log the model with MLflow\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        \n",
    "        print(f\"Model training completed for {model_name}.\")\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(f\"Classification Report:\\n{report}\")\n",
    "        \n",
    "        # Save the trained model to the models folder using joblib\n",
    "        model_path = f'../models/{model_name}_model.pkl'\n",
    "        joblib.dump(model, model_path)\n",
    "        \n",
    "        print(f\"Trained model saved to {model_path}\")\n",
    "        \n",
    "        # Verify that the model can be reloaded successfully\n",
    "        loaded_model = joblib.load(model_path)\n",
    "        if isinstance(loaded_model, type(model)):\n",
    "            print(f\"Model {model_name} loaded successfully as a {type(model).__name__} instance.\")\n",
    "        else:\n",
    "            print(f\"Warning: Model {model_name} did not load as {type(model).__name__}.\")\n",
    "\n",
    "# Initialize models\n",
    "rf_model_fraud = RandomForestClassifier()\n",
    "rf_model_credit = RandomForestClassifier()\n",
    "dt_model_fraud = DecisionTreeClassifier()\n",
    "dt_model_credit = DecisionTreeClassifier()\n",
    "\n",
    "# Train and evaluate Random Forest model on Fraud_Data\n",
    "train_and_evaluate_model(rf_model_fraud, X_train_fraud, X_test_fraud, y_train_fraud, y_test_fraud, 'fraud_detection_rf')\n",
    "\n",
    "# Train and evaluate Random Forest model on Creditcard data\n",
    "train_and_evaluate_model(rf_model_credit, X_train_credit, X_test_credit, y_train_credit, y_test_credit, 'creditcard_fraud_rf')\n",
    "\n",
    "# Train and evaluate Decision Tree model on Fraud_Data\n",
    "train_and_evaluate_model(dt_model_fraud, X_train_fraud, X_test_fraud, y_train_fraud, y_test_fraud, 'fraud_detection_dt')\n",
    "\n",
    "# Train and evaluate Decision Tree model on Creditcard data\n",
    "train_and_evaluate_model(dt_model_credit, X_train_credit, X_test_credit, y_train_credit, y_test_credit, 'creditcard_fraud_dt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
